{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f79cc54e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 52\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m face_mesh\u001b[38;5;241m.\u001b[39mFaceMesh(static_image_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m mesh:\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         ret, frame \u001b[38;5;241m=\u001b[39m \u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m         frame \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mflip(frame, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Flip the image horizontally\u001b[39;00m\n\u001b[0;32m     54\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from mediapipe.python.solutions import face_mesh\n",
    "import math\n",
    "import joblib\n",
    "import winsound  \n",
    "\n",
    "\n",
    "def draw_axes(img, yaw, pitch, roll, tdx=None, tdy=None, size=80):\n",
    "    # bn7awel el zawayaa men degrees le radians 3shan nesta3mel trig functions\n",
    "    pitch = pitch * np.pi / 180\n",
    "    yaw = -yaw * np.pi / 180  # el \"-\" 3shan el direction bet3 yaw mo3akes\n",
    "    roll = roll * np.pi / 180\n",
    "\n",
    "    # lw m3telnash el center point (tdx, tdy), ben7aded nos el sora\n",
    "    if tdx is None or tdy is None:\n",
    "        height, width = img.shape[:2]  # bengeb el height w width mn el sora\n",
    "        tdx = width // 2               # nos el width\n",
    "        tdy = height // 2              # nos el height\n",
    "\n",
    "    # ======================= X Axis (Red) =======================\n",
    "    # bn7seb el makan el gdyd le el x-axis ba3d el lfa (yaw, pitch, roll)\n",
    "    x1 = int(tdx + size * (math.cos(yaw) * math.cos(roll)))\n",
    "    y1 = int(tdy + size * (math.cos(pitch) * math.sin(roll) + math.cos(roll) * math.sin(pitch) * math.sin(yaw)))\n",
    "    # bnrsom el x-axis line bel ahmar\n",
    "    cv2.line(img, (tdx, tdy), (x1, y1), (0, 0, 255), 2)\n",
    "\n",
    "    # ======================= Y Axis (Green) =======================\n",
    "    # bn7seb makan el y-axis ba3d el lfa\n",
    "    x2 = int(tdx + size * (-math.cos(yaw) * math.sin(roll)))\n",
    "    y2 = int(tdy + size * (math.cos(pitch) * math.cos(roll) - math.sin(pitch) * math.sin(yaw) * math.sin(roll)))\n",
    "    # bnrsom el y-axis line bel akhdar\n",
    "    cv2.line(img, (tdx, tdy), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "    # ======================= Z Axis (Blue) =======================\n",
    "    # bn7seb makan el z-axis ba3d el lfa\n",
    "    x3 = int(tdx + size * (math.sin(yaw)))\n",
    "    y3 = int(tdy + size * (-math.cos(yaw) * math.sin(pitch)))\n",
    "    # bnrsom el z-axis line bel azra2\n",
    "    cv2.line(img, (tdx, tdy), (x3, y3), (255, 0, 0), 2)\n",
    "\n",
    "\n",
    "# Load the trained models\n",
    "model_yaw = joblib.load(r\"D:\\senior-2\\semester 2\\Machine Vision\\svm_yaw_model2.pkl\")[\"model\"]\n",
    "model_pitch = joblib.load(r\"D:\\senior-2\\semester 2\\Machine Vision\\svm_pitch_model2.pkl\")[\"model\"]\n",
    "model_roll = joblib.load(r\"D:\\senior-2\\semester 2\\Machine Vision\\svm_roll_model2.pkl\")[\"model\"]\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with face_mesh.FaceMesh(static_image_mode=False) as mesh:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        frame = cv2.flip(frame, 1)  # Flip the image horizontally\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = mesh.process(rgb_frame)\n",
    "\n",
    "        if results.multi_face_landmarks:\n",
    "            for face in results.multi_face_landmarks:\n",
    "                h, w = frame.shape[:2]\n",
    "                x = [int(lm.x * w) for lm in face.landmark]\n",
    "                y = [int(lm.y * h) for lm in face.landmark]\n",
    "\n",
    "                # Normalize as in training\n",
    "                x_centered = np.array(x) - x[99]\n",
    "                y_centered = np.array(y) - y[99]\n",
    "                face_width = np.linalg.norm([x[10]-x[171], y[10]-y[171]])\n",
    "                feature = np.hstack([x_centered, y_centered]) / face_width\n",
    "                feature = feature.reshape(1, -1)\n",
    "\n",
    "                # Predict angles\n",
    "                yaw = model_yaw.predict(feature)[0]\n",
    "                pitch = model_pitch.predict(feature)[0]\n",
    "                roll = model_roll.predict(feature)[0]\n",
    "\n",
    "                # Get nose tip coordinates\n",
    "                nose_tip = face.landmark[1]  \n",
    "                tdx = int(nose_tip.x * w)\n",
    "                tdy = int(nose_tip.y * h)\n",
    "\n",
    "                draw_axes(frame, yaw, pitch, roll, tdx, tdy)\n",
    "\n",
    "                # Display angles on screen\n",
    "                text = f\"Yaw: {yaw:.2f}, Pitch: {pitch:.2f}, Roll: {roll:.2f}\"\n",
    "                cv2.putText(frame, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                            0.8, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "                # Check for excessive pitch or roll\n",
    "                if abs(pitch) > 0.5 or abs(roll) > 0.5:\n",
    "                    cv2.putText(frame, \"WARNING: sleeping driver!\", (10, 70), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.9, (0, 0, 255), 3, cv2.LINE_AA)\n",
    "                    winsound.Beep(1000, 200)  # Play a warning beep\n",
    "\n",
    "        cv2.imshow(\"Head Pose\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35841d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn==1.6.1 in c:\\users\\hodah\\anaconda3\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\hodah\\anaconda3\\lib\\site-packages (from scikit-learn==1.6.1) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\hodah\\anaconda3\\lib\\site-packages (from scikit-learn==1.6.1) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\hodah\\anaconda3\\lib\\site-packages (from scikit-learn==1.6.1) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\hodah\\anaconda3\\lib\\site-packages (from scikit-learn==1.6.1) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn==1.6.1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
