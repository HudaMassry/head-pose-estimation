{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A68b4yxoXUYV",
        "outputId": "f4fe2831-4ead-448c-982a-2ca4391ce2ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.21-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.3.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.2.10)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.2)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (3.10.0)\n",
            "Collecting numpy<2 (from mediapipe)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m368.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.11.0.86)\n",
            "Collecting protobuf<5,>=4.25.3 (from mediapipe)\n",
            "  Downloading protobuf-4.25.7-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.2.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (0.4.1)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (1.15.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
            "Downloading mediapipe-0.10.21-cp311-cp311-manylinux_2_28_x86_64.whl (35.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.7-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sounddevice-0.5.1-py3-none-any.whl (32 kB)\n",
            "Installing collected packages: protobuf, numpy, sounddevice, mediapipe\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.4\n",
            "    Uninstalling protobuf-5.29.4:\n",
            "      Successfully uninstalled protobuf-5.29.4\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.7 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.7 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed mediapipe-0.10.21 numpy-1.26.4 protobuf-4.25.7 sounddevice-0.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install mediapipe\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --force-reinstall --no-cache-dir pandas scipy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1279
        },
        "id": "YRmSRUjKXs31",
        "outputId": "4593ec17-a391-40ef-f129-3f99d0fe691f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pandas\n",
            "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy\n",
            "  Downloading scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m107.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy>=1.23.2 (from pandas)\n",
            "  Downloading numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m113.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dateutil>=2.8.2 (from pandas)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2020.1 (from pandas)\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas)\n",
            "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas)\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.6/37.6 MB\u001b[0m \u001b[31m125.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m94.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m166.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m191.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pytz, tzdata, six, numpy, scipy, python-dateutil, pandas\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2025.2\n",
            "    Uninstalling pytz-2025.2:\n",
            "      Successfully uninstalled pytz-2025.2\n",
            "  Attempting uninstall: tzdata\n",
            "    Found existing installation: tzdata 2025.2\n",
            "    Uninstalling tzdata-2025.2:\n",
            "      Successfully uninstalled tzdata-2025.2\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.17.0\n",
            "    Uninstalling six-1.17.0:\n",
            "      Successfully uninstalled six-1.17.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.15.2\n",
            "    Uninstalling scipy-1.15.2:\n",
            "      Successfully uninstalled scipy-1.15.2\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.9.0.post0\n",
            "    Uninstalling python-dateutil-2.9.0.post0:\n",
            "      Successfully uninstalled python-dateutil-2.9.0.post0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "mediapipe 0.10.21 requires numpy<2, but you have numpy 2.2.5 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.5 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.5 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.7 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.2.5 pandas-2.2.3 python-dateutil-2.9.0.post0 pytz-2025.2 scipy-1.15.2 six-1.17.0 tzdata-2025.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dateutil",
                  "six"
                ]
              },
              "id": "7fc9889de01345379589f23e87598938"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import math\n",
        "import time\n",
        "import cv2\n",
        "import numpy as np\n",
        "import random as rd\n",
        "import pandas as pd\n",
        "import scipy.io as sio\n",
        "import matplotlib.pyplot as plt\n",
        "import mediapipe\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from sklearn import metrics\n",
        "\n"
      ],
      "metadata": {
        "id": "5qU1dZ1wXusg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "DATASET_PATH = '/content/drive/MyDrive/MV/AFLW2000'\n",
        "VIDEO_PATH = '/content/drive/MyDrive/MV/VIDEO'\n",
        "MODELS_PATH = '/content/drive/MyDrive/MV/MODELS'\n",
        "os.makedirs(MODELS_PATH, exist_ok=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1QFY_V2X3jN",
        "outputId": "355d3cb8-dc70-481f-fed3-8c6944779185"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# X_points, Y_points, labels and detected files which are the images thar MediaPipe was able to detect the face\n",
        "x_points= []\n",
        "y_points = []\n",
        "labels = []\n",
        "detected_files = []\n",
        "\n",
        "# extracting the file names (2000 name)\n",
        "\n",
        "file_names = sorted([Path(f).stem for f in glob.glob(DATASET_PATH + '/*.mat')])\n",
        "#By-loop 3ala el directory, we y-geeb asami el files ely fihom el labels.\n",
        "#Bey-sheel .mat we ykhally el base name 3ashan ne-estakhdemo ma3 .jpg sora.\n",
        "\n",
        "\n",
        "\n",
        "# detecting faces and extracting the points\n",
        "faceModule = mediapipe.solutions.face_mesh\n",
        "# looping over the file names to load the images and their corresponding mat file\n",
        "for filename in file_names:\n",
        "  with faceModule.FaceMesh(static_image_mode=True) as faces:   #static_image_mode=True: 3ashan ne2ool le MediaPipe en el sor static mesh video.\n",
        "\n",
        "\n",
        "    # loading the image\n",
        "    image = cv2.imread(DATASET_PATH + '/' + filename + '.jpg')\n",
        "\n",
        "    # processing the image to detect the face and then generating the land marks (468 for each x,y,z).\n",
        "\n",
        "    results = faces.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))  #MediaPipe bey7tag RGB\n",
        "    if results.multi_face_landmarks != None:\n",
        "          # appending the file names where have been detected.\n",
        "          detected_files.append(filename)\n",
        "          # detecting the face\n",
        "          face = results.multi_face_landmarks[0]\n",
        "          # initializing two lists to store the points for the image.\n",
        "          X = []\n",
        "          Y = []\n",
        "          # looping over the 468 points of x and y\n",
        "          for landmark in face.landmark:\n",
        "              x = landmark.x\n",
        "              y = landmark.y\n",
        "              # note: the x and y values are scaled to the their width and height so we will get back their actual value in the image.\n",
        "              shape = image.shape\n",
        "              relative_x = int(x * shape[1])\n",
        "              relative_y = int(y * shape[0])\n",
        "              # X_features\n",
        "              X.append(relative_x)\n",
        "              # Y_features\n",
        "              Y.append(relative_y)\n",
        "\n",
        "          # converting the lists to numpy arrays\n",
        "          X = np.array(X)\n",
        "          Y = np.array(Y)\n",
        "          # appending the points of the images in the list of all image points\n",
        "          x_points.append(X)\n",
        "          y_points.append(Y)\n",
        "\n",
        "          # loading the mat file to extract the labels (pitch,yaw,roll)\n",
        "          mat_file = sio.loadmat(DATASET_PATH + '/' + filename + '.mat')\n",
        "\n",
        "          # extracting the labels 3 angels\n",
        "          pose_param = mat_file[\"Pose_Para\"][0][:3]\n",
        "          # appending the 3 angels to labels list\n",
        "          labels.append(pose_param)\n",
        "\n",
        "# converting features and labels to 2D array\n",
        "x_points = np.array(x_points)\n",
        "y_points = np.array(y_points)\n",
        "labels = np.array(labels)\n",
        "\n",
        "if labels.size > 0:  # Check if labels is not empty\n",
        "    # pitch\n",
        "    pitch_label = labels[:,0]\n",
        "    # yaw\n",
        "    yaw_label = labels[:,1]\n",
        "    # roll\n",
        "    roll_label = labels[:,2]\n",
        "else:\n",
        "    print(\"No faces detected in the dataset. 'labels' array is empty.\")\n",
        "\n",
        "#labels[:, 0] yakhod column el awel (0) yeb2a pitch_label\n",
        "#labels[:, 1]   yakhod column el tany (1) yeb2a yaw_label\n",
        "#labels[:, 2]   yakhod column el talet (2) yeb2a roll_label\n",
        "\n",
        "\n",
        "print(x_points.shape)\n",
        "print(y_points.shape)\n",
        "print(labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUuzJXUxX9DH",
        "outputId": "382d7995-fd36-4ce9-9400-6919bfa7b953"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1853, 468)\n",
            "(1853, 468)\n",
            "(1853, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_center = x_points - x_points[:,99].reshape(-1,1)\n",
        "y_center = y_points - y_points[:,99].reshape(-1,1)\n",
        "\n",
        "# normalizing the data\n",
        "#Points 10 & 171 homa landmarks fe ganbeen el face (left and right).\n",
        "#E7na benesta3mlhom 3ashan n7seb el distance between two cheeks el width of the face.\n",
        "X_171 = x_points[:,171]\n",
        "X_10 = x_points[:,10]\n",
        "Y_171 = y_points[:,171]\n",
        "Y_10 = y_points[:,10]\n",
        "\n",
        "# computing the distance\n",
        "#Dah el Euclidean distance between the two cheek points, 3ashan n3ml normalization lel size el wesh.\n",
        "distance = np.linalg.norm(np.array((X_10,Y_10)) - np.array((X_171,Y_171)),axis = 0).reshape(-1,1)\n",
        "Norm_x = x_center / distance\n",
        "Norm_y = y_center / distance\n",
        "final_x = Norm_x\n",
        "final_y = Norm_y\n",
        "features = np.hstack([final_x,final_y])"
      ],
      "metadata": {
        "id": "VleI3Mk8cW2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def detect_outliers_iqr(data, label_name):\n",
        "    Q1 = np.percentile(data, 25)\n",
        "    Q3 = np.percentile(data, 75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    outlier_mask = (data < lower_bound) | (data > upper_bound)\n",
        "    count = np.sum(outlier_mask)\n",
        "    print(f\"{label_name}: {count} outliers detected\")\n",
        "    return outlier_mask\n",
        "\n",
        "# Detect outliers individually\n",
        "pitch_outliers = detect_outliers_iqr(labels[:, 0], \"Pitch\")\n",
        "yaw_outliers   = detect_outliers_iqr(labels[:, 1], \"Yaw\")\n",
        "roll_outliers  = detect_outliers_iqr(labels[:, 2], \"Roll\")\n",
        "\n",
        "# Combine all detected outliers\n",
        "combined_outliers = pitch_outliers | yaw_outliers | roll_outliers\n",
        "print(f\"\\nTotal outlier samples to remove: {np.sum(combined_outliers)}\")\n",
        "\n",
        "# Filter the data\n",
        "features_cleaned = features[~combined_outliers]\n",
        "labels_cleaned = labels[~combined_outliers]\n",
        "\n",
        "print(f\"Original dataset size: {len(labels)}\")\n",
        "print(f\"Cleaned dataset size: {len(labels_cleaned)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GuBqJdcEwfJ",
        "outputId": "a057ad0a-e320-418d-af26-df7d1f47411c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pitch: 109 outliers detected\n",
            "Yaw: 134 outliers detected\n",
            "Roll: 141 outliers detected\n",
            "\n",
            "Total outlier samples to remove: 273\n",
            "Original dataset size: 1853\n",
            "Cleaned dataset size: 1580\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R6INjttLE1vD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaned labels for pitch, yaw, and roll\n",
        "pitch_label_cleaned = labels_cleaned[:, 0]\n",
        "yaw_label_cleaned = labels_cleaned[:, 1]\n",
        "roll_label_cleaned = labels_cleaned[:, 2]\n",
        "\n",
        "# Step 1: Create empty list to store orientation categories\n",
        "orientation_labels = []\n",
        "\n",
        "# Step 2: Loop over all samples\n",
        "for pitch, yaw in zip(pitch_label_cleaned, yaw_label_cleaned):\n",
        "    if yaw > 0.5:\n",
        "        orientation_labels.append(\"Left\")\n",
        "    elif yaw < -0.5:\n",
        "        orientation_labels.append(\"Right\")\n",
        "    elif pitch > 0.5:\n",
        "        orientation_labels.append(\"Up\")\n",
        "    elif pitch < -0.3:\n",
        "        orientation_labels.append(\"Down\")\n",
        "    else:\n",
        "        orientation_labels.append(\"Front\")\n",
        "\n",
        "# Step 3: Encode the text labels\n",
        "label_encoder = LabelEncoder()\n",
        "orientation_encoded = label_encoder.fit_transform(orientation_labels)\n",
        "\n",
        "# Check examples\n",
        "print(orientation_labels[:10])\n",
        "print(orientation_encoded[:10])\n",
        "print(label_encoder.classes_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbgxSZwVckHy",
        "outputId": "e9454f87-7dea-41c7-b7af-b5271a821f06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Down', 'Left', 'Front', 'Front', 'Front', 'Front', 'Front', 'Front', 'Front', 'Front']\n",
            "[0 2 1 1 1 1 1 1 1 1]\n",
            "['Down' 'Front' 'Left' 'Right']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "# Split into train, val, test\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(features_cleaned, orientation_encoded, test_size=0.4, random_state=1) # hna5od 60% training, 20% val, 20% testing\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=1)\n",
        "\n",
        "# Use validation_data=(X_val, y_val) during training\n",
        "# Evaluate on X_test/y_test after training\n",
        "\n",
        "# Convert labels to one-hot encoding (for softmax classification)\n",
        "y_train_cat = tf.keras.utils.to_categorical(y_train, num_classes=5)\n",
        "y_val_cat = tf.keras.utils.to_categorical(y_val, num_classes=5)\n",
        "y_test_cat = tf.keras.utils.to_categorical(y_test, num_classes=5)\n",
        "\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"y_train shape:\", y_train_cat.shape)\n",
        "\n",
        "print(\"Classes:\", label_encoder.classes_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJXbG4GWdApu",
        "outputId": "aed80a92-b2c8-4d4e-d447-f30dc9e6d859"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (948, 936)\n",
            "y_train shape: (948, 5)\n",
            "Classes: ['Down' 'Front' 'Left' 'Right']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Build the model\n",
        "model = models.Sequential([\n",
        "    layers.Input(shape=(features.shape[1],)),   # Input = 936\n",
        "\n",
        "    # Encoder part\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "\n",
        "    # Decoder part\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(5, activation='softmax')       # 5 classes\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer='nadam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "YwFQ1IOndxON",
        "outputId": "f47af6f0-5c5a-42c2-da1c-43f57619470f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m479,744\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m645\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">479,744</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m644,613\u001b[0m (2.46 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">644,613</span> (2.46 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m644,613\u001b[0m (2.46 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">644,613</span> (2.46 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential([\n",
        "    layers.Input(shape=(features.shape[1],)),\n",
        "\n",
        "    # Encoder\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.BatchNormalization(),  # Stabilize training\n",
        "    layers.Dropout(0.3),\n",
        "\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.2),\n",
        "\n",
        "    # Decoder\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(5, activation='softmax')\n",
        "])\n",
        "from tensorflow.keras.optimizers import Nadam\n",
        "\n",
        "# Customize optimizer with learning rate and decay\n",
        "optimizer = Nadam(\n",
        "    learning_rate=0.001,  # Adjust learning rate (default: 0.002)\n",
        "    beta_1=0.9,           # Momentum\n",
        "    beta_2=0.999          # Momentum for squared gradients\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "hHSWTO_NLwIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train, y_train_cat,\n",
        "    validation_data=(X_val, y_val_cat),\n",
        "    epochs=50,\n",
        "    batch_size=64\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CT906BpKd3UY",
        "outputId": "fe1fcccc-a279-4358-8cf9-3046e0d32033"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.4873 - loss: 1.5300 - val_accuracy: 0.6424 - val_loss: 1.2402\n",
            "Epoch 2/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8161 - loss: 0.5180 - val_accuracy: 0.6772 - val_loss: 1.0954\n",
            "Epoch 3/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8386 - loss: 0.4137 - val_accuracy: 0.6297 - val_loss: 0.9052\n",
            "Epoch 4/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8322 - loss: 0.4257 - val_accuracy: 0.7152 - val_loss: 0.8791\n",
            "Epoch 5/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8415 - loss: 0.4080 - val_accuracy: 0.6772 - val_loss: 0.8331\n",
            "Epoch 6/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8745 - loss: 0.3144 - val_accuracy: 0.6962 - val_loss: 0.8475\n",
            "Epoch 7/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8354 - loss: 0.3886 - val_accuracy: 0.6551 - val_loss: 0.8939\n",
            "Epoch 8/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8500 - loss: 0.3967 - val_accuracy: 0.6361 - val_loss: 0.9068\n",
            "Epoch 9/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8545 - loss: 0.3662 - val_accuracy: 0.6551 - val_loss: 0.9091\n",
            "Epoch 10/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8688 - loss: 0.3208 - val_accuracy: 0.6519 - val_loss: 0.8848\n",
            "Epoch 11/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8690 - loss: 0.3525 - val_accuracy: 0.6582 - val_loss: 0.8597\n",
            "Epoch 12/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8761 - loss: 0.3186 - val_accuracy: 0.6867 - val_loss: 0.7456\n",
            "Epoch 13/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8853 - loss: 0.3113 - val_accuracy: 0.7089 - val_loss: 0.6789\n",
            "Epoch 14/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8677 - loss: 0.3206 - val_accuracy: 0.7247 - val_loss: 0.7104\n",
            "Epoch 15/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.8624 - loss: 0.3144 - val_accuracy: 0.7152 - val_loss: 0.7825\n",
            "Epoch 16/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.8798 - loss: 0.3102 - val_accuracy: 0.7405 - val_loss: 0.7250\n",
            "Epoch 17/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8347 - loss: 0.3934 - val_accuracy: 0.7437 - val_loss: 0.7341\n",
            "Epoch 18/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.8624 - loss: 0.3174 - val_accuracy: 0.7468 - val_loss: 0.6535\n",
            "Epoch 19/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.8883 - loss: 0.2779 - val_accuracy: 0.7722 - val_loss: 0.5557\n",
            "Epoch 20/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8654 - loss: 0.3187 - val_accuracy: 0.7658 - val_loss: 0.5550\n",
            "Epoch 21/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8802 - loss: 0.2954 - val_accuracy: 0.7722 - val_loss: 0.5412\n",
            "Epoch 22/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8828 - loss: 0.3055 - val_accuracy: 0.7690 - val_loss: 0.6315\n",
            "Epoch 23/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8834 - loss: 0.2908 - val_accuracy: 0.7848 - val_loss: 0.5813\n",
            "Epoch 24/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8564 - loss: 0.3434 - val_accuracy: 0.7880 - val_loss: 0.6142\n",
            "Epoch 25/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8715 - loss: 0.3080 - val_accuracy: 0.8133 - val_loss: 0.5366\n",
            "Epoch 26/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8823 - loss: 0.3028 - val_accuracy: 0.7943 - val_loss: 0.6064\n",
            "Epoch 27/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8758 - loss: 0.2914 - val_accuracy: 0.8133 - val_loss: 0.4525\n",
            "Epoch 28/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8690 - loss: 0.2849 - val_accuracy: 0.7848 - val_loss: 0.4776\n",
            "Epoch 29/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8855 - loss: 0.2733 - val_accuracy: 0.8259 - val_loss: 0.4442\n",
            "Epoch 30/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8779 - loss: 0.3172 - val_accuracy: 0.8513 - val_loss: 0.3780\n",
            "Epoch 31/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8549 - loss: 0.3254 - val_accuracy: 0.8418 - val_loss: 0.4200\n",
            "Epoch 32/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8727 - loss: 0.3023 - val_accuracy: 0.8291 - val_loss: 0.4368\n",
            "Epoch 33/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8820 - loss: 0.3042 - val_accuracy: 0.8323 - val_loss: 0.4048\n",
            "Epoch 34/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8653 - loss: 0.2708 - val_accuracy: 0.8418 - val_loss: 0.4292\n",
            "Epoch 35/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8761 - loss: 0.2890 - val_accuracy: 0.8354 - val_loss: 0.4014\n",
            "Epoch 36/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8959 - loss: 0.2693 - val_accuracy: 0.8038 - val_loss: 0.4745\n",
            "Epoch 37/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8857 - loss: 0.2656 - val_accuracy: 0.8418 - val_loss: 0.4023\n",
            "Epoch 38/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8760 - loss: 0.2914 - val_accuracy: 0.8418 - val_loss: 0.3998\n",
            "Epoch 39/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.8736 - loss: 0.2755 - val_accuracy: 0.8038 - val_loss: 0.4462\n",
            "Epoch 40/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.8998 - loss: 0.2269 - val_accuracy: 0.8544 - val_loss: 0.3660\n",
            "Epoch 41/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.8902 - loss: 0.2385 - val_accuracy: 0.8101 - val_loss: 0.4249\n",
            "Epoch 42/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.8921 - loss: 0.2653 - val_accuracy: 0.8323 - val_loss: 0.4753\n",
            "Epoch 43/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8884 - loss: 0.2621 - val_accuracy: 0.8228 - val_loss: 0.5310\n",
            "Epoch 44/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8859 - loss: 0.2563 - val_accuracy: 0.8386 - val_loss: 0.4159\n",
            "Epoch 45/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9053 - loss: 0.2459 - val_accuracy: 0.8228 - val_loss: 0.4350\n",
            "Epoch 46/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8705 - loss: 0.2681 - val_accuracy: 0.8513 - val_loss: 0.4352\n",
            "Epoch 47/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8922 - loss: 0.2457 - val_accuracy: 0.8070 - val_loss: 0.4804\n",
            "Epoch 48/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8857 - loss: 0.2616 - val_accuracy: 0.8196 - val_loss: 0.5181\n",
            "Epoch 49/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8778 - loss: 0.2685 - val_accuracy: 0.8481 - val_loss: 0.4322\n",
            "Epoch 50/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9043 - loss: 0.2465 - val_accuracy: 0.8513 - val_loss: 0.3918\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(X_test, y_test_cat, verbose=0)\n",
        "print(f\"\\nFinal Test Accuracy: {test_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwCwhUfAKtgV",
        "outputId": "0e8799a7-9261-4e7f-d81c-799e7db5e550"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Test Accuracy: 0.8924\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained CNN model\n",
        "model.save('head_orientation_classifier.h5')\n",
        "from google.colab import files\n",
        "files.download('head_orientation_classifier.h5')\n"
      ],
      "metadata": {
        "id": "KpvhCMQ-lw6w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}